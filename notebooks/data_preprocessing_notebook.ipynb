{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcd22fd",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook focuses on preprocessing the raw Telegram e-commerce data collected for the **Ethio Ecom NER Analytics** project. The goal is to transform the scraped messages into a clean, tokenized format suitable for training an Amharic Named Entity Recognition (NER) model. The process addresses Amharic-specific linguistic features, handles missing data, and prepares the dataset for downstream tasks like entity extraction and vendor analytics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52236a67",
   "metadata": {},
   "source": [
    "### Scripts and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9949f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from scripts.preprocess_messages import clean_amharic_message, tokenize_amharic_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f33ed",
   "metadata": {},
   "source": [
    "### Reading Data and Initial Inspection\n",
    "The raw data, scraped from Telegram channels, is loaded from `../data/raw/telegram_data.csv` with UTF-8 encoding to support Amharic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape:\n",
      "(39261, 6)\n",
      "  Channel Title         Channel Username    ID  \\\n",
      "0   EthioBrand®  @ethio_brand_collection  6117   \n",
      "1   EthioBrand®  @ethio_brand_collection  6116   \n",
      "2   EthioBrand®  @ethio_brand_collection  6115   \n",
      "3   EthioBrand®  @ethio_brand_collection  6114   \n",
      "4   EthioBrand®  @ethio_brand_collection  6113   \n",
      "\n",
      "                                             Message  \\\n",
      "0  ‼️ እሁድ ሁሌም ክፍት ነን ‼️\\n\\nReebok Club Vintage   ...   \n",
      "1  Skechers archfit \\nsize 40,41,42,43\\nPrice 340...   \n",
      "2  ‼️ እሁድ ሁሌም ክፍት ነን ‼️\\n\\nNB 04 leather  \\nSize ...   \n",
      "3                                                NaN   \n",
      "4  Nike Air Force Paisley \\nSize 40,41,42,43,44\\n...   \n",
      "\n",
      "                        Date  Media Path  \n",
      "0  2025-06-22 06:27:39+00:00         NaN  \n",
      "1  2025-06-16 09:01:34+00:00         NaN  \n",
      "2  2025-06-15 09:20:06+00:00         NaN  \n",
      "3  2025-06-15 09:16:19+00:00         NaN  \n",
      "4  2025-06-14 09:04:17+00:00         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV with better handling of quotes and encoding\n",
    "df = pd.read_csv(\"../data/raw/telegram_data.csv\", encoding='utf-8')\n",
    "\n",
    "# Initial inspection of the DataFrame\n",
    "print(\"Initial DataFrame shape:\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5f27d",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- **Shape (39261, 6):** Indicates 39,261 messages with 6 columns (`Channel Title`, `Channel Username`, `ID`, `Message`, `Date`, `Media Path`).\n",
    "- **Missing Data:** Row 3 shows a `NaN` in `Message`, suggesting incomplete posts.\n",
    "- **Amharic Content:** Messages like \"እሁድ ሁሌም ክፍት ነን\" (meaning \"We are always open on Sunday\") confirm Amharic usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf7567",
   "metadata": {},
   "source": [
    "### Preprocessing and Tokenization\n",
    "#### Step-by-Step Processing\n",
    "\n",
    "1. **Drop Rows with Missing or Empty Messages**\n",
    "   - Removes `NaN` values and empty strings to ensure data quality.\n",
    "2. **Flatten Internal Newlines**\n",
    "   - Replaces newlines (`\\n`) and carriage returns (`\\r`) with spaces for uniform text.\n",
    "3. **Strip Leading/Trailing Spaces**\n",
    "   - Cleans up extra whitespace.\n",
    "4. **Drop 'Media Path' Column**\n",
    "   - Removes the irrelevant `Media Path` column since images were not downloaded.\n",
    "5. **Reset Index**\n",
    "   - Reindexes the DataFrame after filtering.\n",
    "6. **Clean Messages**\n",
    "   - Applies `clean_amharic_message` to remove non-Amharic characters (e.g., emojis) while preserving Amharic script, English, numbers, and basic punctuation.\n",
    "7. **Tokenize Messages**\n",
    "   - Uses `tokenize_amharic_text` to split cleaned text into word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664d6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop rows with missing or empty messages\n",
    "df = df[df['Message'].notna()]  # Remove NaN\n",
    "df = df[df['Message'].str.strip() != '']  # Remove empty or whitespace-only strings\n",
    "\n",
    "# 2. Flatten internal newlines\n",
    "df['Message'] = df['Message'].str.replace('\\n', ' ', regex=False).str.replace('\\r', '', regex=False)\n",
    "\n",
    "# 3. Strip leading/trailing spaces\n",
    "df['Message'] = df['Message'].str.strip()\n",
    "\n",
    "# 4. Drop 'Media Path' column\n",
    "if 'Media Path' in df.columns:\n",
    "    df = df.drop(columns=['Media Path'])\n",
    "\n",
    "# 5. Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 6. Clean messages using the provided function\n",
    "df['Message'] = df['Message'].apply(clean_amharic_message)\n",
    "\n",
    "# 7. Tokenize messages\n",
    "df['Message'] = df['Message'].apply(tokenize_amharic_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47a2cd",
   "metadata": {},
   "source": [
    "### Output Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794c64c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing:\n",
      "(21689, 5)\n",
      "  Channel Title         Channel Username    ID  \\\n",
      "0   EthioBrand®  @ethio_brand_collection  6117   \n",
      "1   EthioBrand®  @ethio_brand_collection  6116   \n",
      "2   EthioBrand®  @ethio_brand_collection  6115   \n",
      "3   EthioBrand®  @ethio_brand_collection  6113   \n",
      "4   EthioBrand®  @ethio_brand_collection  6112   \n",
      "\n",
      "                                             Message  \\\n",
      "0  [እሁድ, ሁሌም, ክፍት, ነን, Reebok, Club, Vintage, siz...   \n",
      "1  [Skechers, archfit, size, 40,41,42,43, Price, ...   \n",
      "2  [እሁድ, ሁሌም, ክፍት, ነን, NB, 04, leather, Size, 39,...   \n",
      "3  [Nike, Air, Force, Paisley, Size, 40,41,42,43,...   \n",
      "4  [Skechers, GY, ULTRA, Size, 40,41,42,43,44, Pr...   \n",
      "\n",
      "                        Date  \n",
      "0  2025-06-22 06:27:39+00:00  \n",
      "1  2025-06-16 09:01:34+00:00  \n",
      "2  2025-06-15 09:20:06+00:00  \n",
      "3  2025-06-14 09:04:17+00:00  \n",
      "4  2025-06-14 06:40:06+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Inspection after preprocessing\n",
    "print(\"After preprocessing:\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915894cb",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- **Shape (21689, 5):** Reduced rows indicate removal of 17,572 invalid entries (e.g., `NaN` or empty messages).\n",
    "- **Tokenized Output:** Messages are now lists of tokens (e.g., `[እሁድ, ሁሌም, ክፍት, ነን]`), ready for NER labeling in CoNLL format.\n",
    "- **Data Integrity:** Amharic tokens are preserved, ensuring compatibility with the NER model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bdff2c",
   "metadata": {},
   "source": [
    "### Saving Preprocessed Data\n",
    "The processed dataset is saved to `../data/processed/preprocessed_messages.csv` with UTF-8-SIG encoding to handle special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b893d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to: ../data/processed/preprocessed_messages.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV in ../data/processed/\n",
    "output_path = \"../data/processed/preprocessed_messages.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')  # utf-8-sig to handle special characters like እሁድ\n",
    "\n",
    "print(f\"Preprocessed data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6597b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Next Steps\n",
    "1. **Labeling:** Convert tokenized data into CoNLL format for NER training.\n",
    "2. **Analysis:** Explore token frequency for initial entity insights.\n",
    "\n",
    "This notebook lays the groundwork for creating a high-quality dataset, critical for the success of the NER model and vendor analytics pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
